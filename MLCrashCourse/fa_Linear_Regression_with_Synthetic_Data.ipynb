{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlpUL0UbGtjIem+0aL4Rxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhazalehKeyvani/Avina/blob/main/MLCrashCourse/fa_Linear_Regression_with_Synthetic_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#رگرسیون خطی با داده های مصنوعی"
      ],
      "metadata": {
        "id": "_KYmHrgAKwF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Hyperparametrs\n",
        "\n",
        "*   Learning rate\n",
        "*   Epochs\n",
        "\n",
        "\n",
        "*   Batch size\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q2jeH7uBLb1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FDsgMoaHXNrS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##تعریف توابع برای ساخت و آموزش مدل\n",
        "\n",
        "\n",
        "\n",
        "*   build_model(my_learning_rate) --->ساخت مدل خالی\n",
        "*   train_model(model, feature, lable, epochs)--->مدل از مثال ها که حاوی ویژگی و برچسب هستند آموزش می بیند\n",
        "\n",
        "\n",
        "فعلا لازم نیست محتوای تعریف این توابع را یاد بگیرید\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HOZybuswPtTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    # A sequential model contains one or more layers.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Describe the topography of the model.\n",
        "    # The topography of a simple linear regression model\n",
        "    # is a single node in a single layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,\n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "    # Compile the model topography into code that\n",
        "    # TensorFlow can efficiently execute. Configure\n",
        "    # training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  return model\n",
        "\n",
        "def train_model(model, df, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the feature values and the label values to the\n",
        "  # model. The model will train for the specified number\n",
        "  # of epochs, gradually learning how the feature values\n",
        "  # relate to the label values.\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the\n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Gather the history (a snapshot) of each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # Specifically gather the model's root mean\n",
        "  # squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "print(\"Defined build_model and train_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLI4PlzyPozb",
        "outputId": "ce75f73c-0871-467a-9c78-47c816a116ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined build_model and train_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##تعریف توابع رسم نمودار\n",
        "\n",
        "\n",
        "\n",
        "> ما با matplotlib نمودار های زیر رارسم می کنیم\n",
        "\n",
        "\n",
        "*   یک نمودار از ارزش ویژگی ها و ارزش برچسب ها و یک خط خروجی از مدل آموزش دیده\n",
        "*   منحنی loss\n",
        "\n"
      ],
      "metadata": {
        "id": "shnX-gFWR4vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define the plotting functions\n",
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
        "\n",
        "  # Label the axes.\n",
        "  plt.xlabel(\"feature\")\n",
        "  plt.ylabel(\"label\")\n",
        "\n",
        "  # Plot the feature values vs. label values.\n",
        "  plt.scatter(feature, label)\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = feature[-1]\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQLF_C9BUaKQ",
        "outputId": "71c29372-3042-4e14-ec76-11599906f978"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_model and plot_the_loss_curve functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##تعریف دیتاست\n",
        "\n",
        "دوازده مثال\n",
        " با یک ویژگی و یک برچسب"
      ],
      "metadata": {
        "id": "DNILTlRtB9hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
        "my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"
      ],
      "metadata": {
        "id": "pMo3khZgB_NS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##مشخص کردن hyperparameters\n",
        "\n",
        "\n",
        "*   Learning rate\n",
        "*   Epochs\n",
        "*   batch_size"
      ],
      "metadata": {
        "id": "EPXpw1IJVCbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view a possible solution\n",
        "learning_rate=0.01\n",
        "epochs=16\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "VTDxrD7XV8DC",
        "outputId": "a2c099f6-d3b6-4946-8d6a-d3cb57e05301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 1 required positional argument: 'batch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d40f4463158c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                          \u001b[0mmy_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                          my_batch_size)\n",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 1 required positional argument: 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "تمرین 1 :امتحان کردن گراف ها\n",
        "\n",
        "نمودار بالا را بررسی کنید. نقاط آبی داده های واقعی را مشخص می کند. خط قرمز خروجی مدل آموزش دیده را مشخص می کند. در حالت ایده آل، خط قرمز باید به خوبی با نقاط آبی هماهنگ شود. آیا آن را انجام می دهد؟ احتمالا نه.\n",
        "\n",
        "مقدار مشخصی تصادفی در آموزش یک مدل نقش دارد، بنابراین هر بار که تمرین می کنید نتایج متفاوتی دریافت خواهید کرد. گفته می شود، مگر اینکه فرد بسیار خوش شانسی باشید، خط قرمز احتمالاً به خوبی با نقاط آبی هماهنگ نیست.\n",
        "\n",
        "نمودار پایین را که منحنی ضرر را نشان می دهد، بررسی کنید. توجه داشته باشید که منحنی ضرر کاهش می یابد اما صاف نمی شود، که نشانه آن است که مدل به اندازه کافی تمرین نکرده است."
      ],
      "metadata": {
        "id": "tiVoyQm0WrtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "تمرین 2 : افزایش تعداد epochs\n",
        "از دست دادن تمرین باید به طور پیوسته کاهش یابد، در ابتدا به شدت و سپس آهسته تر. در نهایت، از دست دادن تمرین باید ثابت بماند (شیب صفر یا شیب تقریبا صفر)، که نشان می دهد تمرین همگرا شده است.\n",
        "\n",
        "در کار 1، از دست دادن آموزش همگرا نشد. یکی از راه حل های ممکن، آموزش برای دوره های بیشتر است. وظیفه شما این است که تعداد دوره ها را به اندازه کافی افزایش دهید تا مدل همگرا شود. با این حال، آموزش همگرایی گذشته ناکارآمد است، بنابراین فقط تعداد دوره ها را روی مقدار دلخواه بالا قرار ندهید.\n",
        "\n",
        "منحنی ضرر را بررسی کنید. آیا مدل همگرا می شود؟"
      ],
      "metadata": {
        "id": "05n0x3T7hNr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view a possible solution\n",
        "learning_rate=0.01\n",
        "epochs=450\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "# The loss curve suggests that the model does converge."
      ],
      "metadata": {
        "id": "A0JRge2RAZjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "70aac028-c2c4-4218-ecc0-cc22c004261f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 1 required positional argument: 'batch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-823b524fe78e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                          \u001b[0mmy_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                          my_batch_size)\n",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 1 required positional argument: 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tAE8TDYWAX4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the learning rate and decrease the number of epochs.\n",
        "learning_rate=100\n",
        "epochs=500\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ],
      "metadata": {
        "id": "1e2tRcHJd6VX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "0ff2f4ff-cb2e-47b7-bb68-9202a1cb0ea0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 1 required positional argument: 'batch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d86865de9267>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                          \u001b[0mmy_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                          my_batch_size)\n",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 1 required positional argument: 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "تمرین 4 : پیداکردن ترکیب ایده آلی از epochs و learning rate\n",
        "\n",
        "\n",
        "> این دو را به گونه ای تغییر دهید که داده ها با نمودار  پیش بینی همگرا شوند\n",
        "\n"
      ],
      "metadata": {
        "id": "BUPuQ-TMvOG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view a possible solution\n",
        "\n",
        "learning_rate=0.14\n",
        "epochs=70\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ],
      "metadata": {
        "id": "7Gn2Vg_BxtN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "142b372c-cda4-4c34-c8d1-15c85ccdc078"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 1 required positional argument: 'batch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a070ca7deaed>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                          \u001b[0mmy_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                          my_batch_size)\n",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 1 required positional argument: 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "تمرین 5 : تنظیم batch size\n",
        "\n",
        "\n",
        "این سیستم ارزش تلفات مدل را مجدداً محاسبه می کند و وزن و بایاس مدل را پس از هر بار تکرار تنظیم می کند. هر تکرار دامنه ای است که در آن سیستم یک دسته را پردازش می کند. به عنوان مثال، اگر اندازه دسته 6 باشد، سیستم مقدار تلفات مدل را مجدداً محاسبه می کند و پس از پردازش هر 6 نمونه، وزن و بایاس مدل را تنظیم می کند.\n",
        "\n",
        "یک دوره تکرارهای کافی برای پردازش هر نمونه در مجموعه داده را در بر می گیرد. به عنوان مثال، اگر اندازه دسته 12 باشد، هر دوره یک تکرار طول می کشد. با این حال، اگر اندازه دسته 6 باشد، هر دوره دو تکرار مصرف می کند.\n",
        "\n",
        "وسوسه انگیز است که به سادگی اندازه دسته را به تعداد نمونه های موجود در مجموعه داده (در این مورد 12) تنظیم کنید. با این حال، این مدل ممکن است در دسته‌های کوچک‌تر سریع‌تر تمرین کند. در مقابل، دسته های بسیار کوچک ممکن است حاوی اطلاعات کافی برای کمک به همگرایی مدل نباشند.\n",
        "\n",
        "با batch_size در سلول کد زیر آزمایش کنید. کوچک‌ترین عدد صحیحی که می‌توانید برای batch_size تنظیم کنید و همچنان مدل در صد دوره همگرا شود چیست؟"
      ],
      "metadata": {
        "id": "3IGRTuCvxwbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view a possible solution\n",
        "\n",
        "learning_rate=0.05\n",
        "epochs=100\n",
        "my_batch_size=1 # Wow, a batch size of 1 works!\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "0M7g44OE5DyX",
        "outputId": "171b9c79-b255-438d-c671-ba762f90a485"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "build_model() takes 1 positional argument but 5 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-455fa4ab9150>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m trained_weight, trained_bias, epochs, rmse = build_model(my_model, my_feature,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                                          \u001b[0mmy_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                          my_batch_size)\n",
            "\u001b[0;31mTypeError\u001b[0m: build_model() takes 1 positional argument but 5 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##خلاصه تنظیم هایپرپارامتر\n",
        "\n",
        "اکثر مشکلات یادگیری ماشین نیاز به تنظیم هایپرپارامتر زیادی دارند. متأسفانه، ما نمی‌توانیم قوانین تنظیم دقیق را برای هر مدل ارائه کنیم. کاهش نرخ یادگیری می‌تواند به همگرایی یک مدل کمک کند، اما باعث می‌شود مدل دیگر خیلی آهسته همگرا شود. شما باید آزمایش کنید تا بهترین مجموعه هایپرپارامترها را برای مجموعه داده خود بیابید. با این حال، در اینجا چند قانون سرانگشتی وجود دارد:\n",
        "\n",
        "\n",
        "* یادگیری loss باید به طور پیوسته کاهش یابد، ابتدا به شدت، و سپس آهسته تر تا زمانی که شیب منحنی به صفر برسد یا به آن نزدیک شود.\n",
        "* اگر یادگیری loss همگرا نشد، برای دوره های بیشتری تمرین کنید. epoch (|^)\n",
        "* اگر یادگیری loss خیلی آهسته کاهش می یابد، سرعت یادگیری را افزایش دهید. توجه داشته باشید که تنظیم نرخ یادگیری بیش از حد ممکن است از همگرا شدن یادگیری loss جلوگیری کند.learning rate(\\|/)\n",
        "* اگر یادگیری loss بسیار متفاوت است (یعنی ضرر تمرین به اطراف می پرد)، میزان یادگیری را کاهش دهید.\n",
        "\n",
        "* کاهش نرخ یادگیری در حالی که تعداد دوره ها یا اندازه دسته ای افزایش می یابد اغلب ترکیب خوبی است.\n",
        "* تنظیم اندازه دسته روی تعداد بسیار کوچک دسته نیز می تواند باعث بی ثباتی شود.\n",
        "* ابتدا، مقادیر اندازه دسته بزرگ را امتحان کنید. سپس، اندازه دسته را کاهش دهید تا زمانی که تخریب را مشاهده کنید.\n",
        "* برای مجموعه داده های دنیای واقعی که از تعداد بسیار زیادی نمونه تشکیل شده است، ممکن است کل مجموعه داده در حافظه جا نگیرد. در چنین مواردی، باید اندازه دسته را کاهش دهید تا batch را در حافظه جا دهید.\n",
        "\n",
        "به یاد داشته باشید: ترکیب ایده آل هایپرپارامترها به داده ها وابسته است، بنابراین همیشه باید آزمایش و تأیید کنید."
      ],
      "metadata": {
        "id": "46IukatX5_ZY"
      }
    }
  ]
}